---
layout: post
title: OpenAI新产品GPTBot
date: 2023-08-08 06:03:00 +0800
excerpt: 可爬取网络数据，为GPT-5做准备
tag: news
cover: /assets/images/posts/100090.png
description: OpenAI新产品GPTBot：可爬取网络数据，为GPT-5做准备
permalink: /100090
---


# {{ page.title }}



8月8日，OpenAI在官网介绍了新产品GPTBot，这是一种网络爬虫，可大规模爬取网络数据用于训练AI模型。（地址：https://platform.openai.com/docs/gptbot）

OpenAI表示，将通过GPTBot抓取海量数据，用于训练、优化未来模型。国外不少科技媒体指出，这个未来模型指的就是GPT-5。

事实上，OpenAI在今年7月18日提交了GPT-5商标的消息，此时又放出全新网络爬虫， 说明GPT-5离我们越来越近了。


> GPTBot介绍

GPTBot是OpenAI的网络爬虫，可以通过以下用户代理和字符串来识别，代码如下。


```
User agent token: GPTBot

Full user-agent string: Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; GPTBot/1.0; +https://openai.com/gptbot)
```


OpenAI会对抓取的数据进行过滤，例如，删除需要付费才能查看、使用的数据，搜集的个人身份信息（PII）或违反法律法规的数据等，以保证抓取的数据符合安全标准。

如果用户的网站不想被GPTBot抓取数据，可以将GPTBot添加到站点的robots.txt中，代码如下：

```
User-agent: GPTBot

Disallow: /
```


用户也可以自定义GPTBot的访问权限，将其添加到网站的robots.txt中，代码如下：


```
User-agent: GPTBot

Allow: /directory-1/

Disallow: /directory-2/
```


> 什么是网络爬虫

网络爬虫，是一种主要通过浏览网络抓取数据的工具，方式包括数据挖掘，网页数据复制/拍照、网站镜像等方式。

网络爬虫是互联网和大数据时代最重要工具之一，被誉为“黄金矿工”应用场景非常广泛。

例如，谷歌、百度等搜索引擎通过网络爬虫来收集和建立网页索引，方便用户可以通过关键字快速找到相关的网页。


也有商业机构使用网络爬虫实时收集竞争对手的信息，如产品价格、新产品发布、营销活动等，以进行市场分析和营销策略制定。

> 网络爬虫的缺点

虽然网络爬虫功能强大，但也存在数据质量不稳定、版权风险、难以爬取特定内容、爬取频率等缺点。

数据质量不稳定：网络爬虫抓取的数据可能包含大量非法、虚假或质量低下的数据，例如，爬取了一个非法网站的数据。因此，想使用爬虫的数据需要进行清洗和处理。

版权风险：网络爬虫可能会侵犯数据隐私和版权，违反网站的使用协议带来法律风险。例如，非法爬取了目标网站的付费内容。



难以爬取特定内容：对于一些需要用户输入或交互才能获取的内容，例如，网站搜索结果、验证码、登录后才能查看的内容等，网络爬虫可能难以抓取。

爬取频率：网络爬虫抓取的数据是静态的，不能实时反映网页的变化需要定期重新抓取。但频率过高会对目标网站的服务器造成巨大压力影响其正常服务，频率太低数据更新又不及时，需要制定一个合理的频率。

如今在大模型等AI技术加持下，上述常见的网络爬虫缺点已得到克服，并且更注重数据版权、安全等问题。

网络爬虫抓取的数据，是训练大语言模型的重要来源

目前，训练大语言模型的主要数据来源包括自有数据集、开源数据集和网络爬虫等。自有数据集主要应用在特定业务场景的微调，例如，法律领域的使用真实的法律裁决、书籍、法律合同等数据，训练专用于法律的生成式AI产品。

开源数据集，这种数据是很多大型厂商开源的数据有的可用于商业化，有的只能用于技术研究，并且数据可能存在老旧的情况。所以，网络爬虫成为企业训练通用大模型的重要数据来源。



例如，OpenAI的GPT-3模型使用了45TB的互联网文本进行训练，包括代码、小说、百科、新闻、博客等，而这些数据来源多数是通过网络爬虫获取。

所以，我们有时候会看到ChatGPT会生成虚假的信息，就是因为在爬取时本身就抓取了错误、虚假的信息，在清洗、预训练、微调的过程中又没发现，才会出现这样的情况（有时也存在AI算法问题等）。

不过OpenAI已经制定了严格的数据获取、使用标准，避免这种情况发生。