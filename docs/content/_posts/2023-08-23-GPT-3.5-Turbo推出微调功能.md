---
layout: post
title: GPT-3.5 Turbo推出微调功能
date: 2023-08-23 06:26:00 +0800
excerpt: 可以打造专属ChatGPT啦
tag: news
cover: /assets/images/posts/100093.png
description: GPT-3.5 Turbo推出微调功能，可以打造专属ChatGPT啦
permalink: /100093
---


# GPT-3.5 Turbo推出微调功能，可以打造专属ChatGPT啦



8月25日，著名开源大模型、数据集平台Hugging Face获得2.35亿美元（约17亿元）D轮融资，估值达到45亿美元（约328亿元）。本次投资包括Salesforce、谷歌、英伟达、AMD、高通、英特尔、IBM、亚马逊等科技巨头。

目前其开源平台提供了50万个模型和25万个数据集，包括文本生成图片、视频、文本、音频、3D等类型。（平台地址：https://huggingface.co/）

Hugging Face能在短时间内迅速崛起，获得巨额融资主要受到了ChatGPT等生成式AI的利好影响。

同时Hugging Face也参与到了生成式AI赛道的竞争，推出了生成式AI聊天机器人HuggingChat、代码开发助手StarCoder和开源大语言模型Bloom。

所以，Hugging Face也是OpenAI、Anthropic、Inflection AI、Cohere等知名AI企业的潜在竞争对手。


资料显示，Hugging Face创立于2016年，总部位于美国纽约。2017年3月获得120万美元种子轮融资；2018年5月获400万美元种子融资；2019年12月获1500万美元A轮；2021年3月获4000万美元B轮；2022年5月获1亿美元C轮。

从上述融资历史不难看出，早期的Hugging Face的发展速度非常平稳。直到2022生成式AI爆发元年到来，Hugging Face获得了一飞冲天的机会。

最初，Hugging Face开发了一款面向青少年教育、心理辅导的AI聊天机器人，与现在爆火的ChatGPT类似。但由于当时技术不成熟功能不完善，没有获得太大的关注和产品影响力。

随后，Hugging Face将该程序开源并发现了开源领域的商机，开始全面转型提供大模型的代码共享、部署、测试、运营等服务。目前，Hugging Face的企业客户超过5万家，典型客户包括微软、谷歌、Meta、AI2、英特尔等知名企业。


产品方面，Hugging Face的开源平台主要提供大模型和数据集，平均每月有10万名用户在其平台上分享代码。

Hugging Face还提供了功能强大的开源机器学习开发工具包括：transformers、diffusers、PEFT、timm和Hub client library等。

Transformers：享誉全球的深度学习模型，GPT系列便是根据此模型开发而成。适用于PyTorch、TensorFlow和JAX最先进的机器学习，支持文本问答、分类、摘要、翻译、识别等。（地址：https://huggingface.co/docs/transformers/index）

Diffusers：目前最先进的预训练扩散模型的首选库，用于生成图像、音频等内容。知名的开源文本生成图片平台stable diffusion，便是基于Diffusers开发而成。（地址：https://huggingface.co/docs/diffusers/index）


PEFT：是一个高效微调的模型库，主要用于预训练的语言模型适应各种下游应用程序，而无需微调所有模型的参数，帮助企业、开发者降低模型微调开发成本和时间，简化大模型开发流程。（地址：https://huggingface.co/docs/peft/index）

Hub client library：这是一个面向开发者的机器学习平台，允许与Hugging Face Hub进行交互，选择适合自己的预训练模型、数据集或机器学习应用。（地址：https://huggingface.co/docs/huggingface_hub/index）


此外，Hugging Face特意针对大语言模型推出了“开源大语言模型排行榜”，非常受开发者的欢迎。

用户可以将开源产品提交到Hugging Face，平台会自动对产品的性能、参数进行自动评估然后进行打分。综合评分高的开源产品，有机会入选该榜单。

